{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0515be6f",
   "metadata": {},
   "source": [
    "## **Lab2 - Data Collection and Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e8e90",
   "metadata": {},
   "source": [
    "**Name:** Mandeep Singh Brar  \n",
    "**ID Number:** 8989367  \n",
    "**Course Name:** Machine Learning Programming  \n",
    "**Course Code:** PROG8245"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495c7e",
   "metadata": {},
   "source": [
    "### **Step 1:** Hello, Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "235d0eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Order ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Order Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Customer ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Quantity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "City",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8f7d1f80-a1eb-4c1b-b864-4aafabf9f85f",
       "rows": [
        [
         "0",
         "CA-2016-152156",
         "11/8/2016",
         "CG-12520",
         "FUR-BO-10001798",
         "Bush Somerset Collection Bookcase",
         "Furniture",
         "261.96",
         "2.0",
         "Henderson"
        ],
        [
         "1",
         "CA-2016-152156",
         "11/8/2016",
         "CG-12520",
         "FUR-CH-10000454",
         "Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back",
         "Furniture",
         "731.94",
         "3.0",
         "Henderson"
        ],
        [
         "2",
         "CA-2016-138688",
         "6/12/2016",
         "DV-13045",
         "OFF-LA-10000240",
         "Self-Adhesive Address Labels for Typewriters by Universal",
         "Office Supplies",
         "14.62",
         "2.0",
         "Los Angeles"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>261.96</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Henderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>731.94</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Henderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>6/12/2016</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>14.62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order ID Order Date Customer ID       Product ID  \\\n",
       "0  CA-2016-152156  11/8/2016    CG-12520  FUR-BO-10001798   \n",
       "1  CA-2016-152156  11/8/2016    CG-12520  FUR-CH-10000454   \n",
       "2  CA-2016-138688  6/12/2016    DV-13045  OFF-LA-10000240   \n",
       "\n",
       "                                        Product Name         Category   Sales  \\\n",
       "0                  Bush Somerset Collection Bookcase        Furniture  261.96   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...        Furniture  731.94   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...  Office Supplies   14.62   \n",
       "\n",
       "   Quantity         City  \n",
       "0       2.0    Henderson  \n",
       "1       3.0    Henderson  \n",
       "2       2.0  Los Angeles  "
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd     # pandas is used for data loading, cleaning, and analysis\n",
    "import numpy as np      # numpy is used for efficient numerical operations (e.g., for missing values)\n",
    "import matplotlib.pyplot as plt  # matplotlib is used for creating data visualizations like plots and charts\n",
    "import seaborn as sns   # seaborn is a statistical data visualization, great for advanced visualizations\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('c:/Users/singh/Desktop/500 Sales Records.csv')\n",
    "\n",
    "# Display the first 3 rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918761f",
   "metadata": {},
   "source": [
    "### **Step 2:** Pick the Right Container\n",
    "\n",
    "**Dict** stores sales data flexibly but can be messy. **namedtuple** is cleaner for fixed columns. **class** is best if we want to add methods like profit calculation.\n",
    "\n",
    "**Conclusion:**\n",
    "For above dataset, a custom class is most useful if we are planning to add data validation or extra logic. For simply storing and accessing rows, a namedtuple is clean and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e9117",
   "metadata": {},
   "source": [
    "### **Step 3:** Transaction Class and OO Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "e3da11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction class defined.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime # For converting date strings into Python date objects\n",
    "from typing import Optional # For type hinting optional fields in the Transaction class\n",
    "\n",
    "class Transaction:\n",
    "    def __init__(ecommerce, \n",
    "                 order_id, \n",
    "                 order_date, \n",
    "                 customer_id, \n",
    "                 product_id, \n",
    "                 product_name, \n",
    "                 category, \n",
    "                 sales, \n",
    "                 quantity, \n",
    "                 city):\n",
    "        ecommerce.order_id = order_id\n",
    "        ecommerce.order_date = datetime.strptime(order_date, '%m/%d/%Y')\n",
    "        ecommerce.customer_id = customer_id\n",
    "        ecommerce.product_id = product_id\n",
    "        ecommerce.product_name = product_name\n",
    "        ecommerce.category = category\n",
    "        ecommerce.sales = float(sales)\n",
    "        ecommerce.quantity = int(quantity)\n",
    "        ecommerce.city = city\n",
    "\n",
    "    def __sale__(ecommerce):\n",
    "        return f\"Transaction({ecommerce.order_id}, {ecommerce.sales}, {ecommerce.city})\"\n",
    "\n",
    "print(\"Transaction class defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38339b15",
   "metadata": {},
   "source": [
    "### **Step 4:** Bulk Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "9be9f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 transactions.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "# Function to load transactions from a DataFrame\n",
    "def load_transactions(df) -> List[Transaction]:\n",
    "    transactions = [] # Empty list to store Transaction objects\n",
    "\n",
    "    # Loop through each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        # Create a Transaction object from row data\n",
    "        transactions.append(Transaction(\n",
    "            row['Order ID'],\n",
    "            row['Order Date'],\n",
    "            row['Customer ID'],\n",
    "            row['Product ID'],\n",
    "            row['Product Name'],\n",
    "            row['Category'],\n",
    "            row['Sales'],\n",
    "            row['Quantity'],\n",
    "            row['City']\n",
    "        ))\n",
    "    return transactions\n",
    "\n",
    "transactions = load_transactions(df)\n",
    "print(f\"Loaded {len(transactions)} transactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def5c343",
   "metadata": {},
   "source": [
    "### **Step 5:** Quick Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "3c676ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ QUICK PROFILING ------\n",
      "Minimum Sales: 1.25\n",
      "Mean Sales: 258.85\n",
      "Maximum Sales: 8159.95\n",
      "Number of Unique Cities: 117\n",
      "Sample Cities: ['Tampa', 'West Jordan', 'Columbia', 'Henderson', 'Amarillo']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Collect all sales values and unique cities from the transactions list.\n",
    "sales_values = [t.sales for t in transactions]\n",
    "unique_cities = {t.city for t in transactions}\n",
    "\n",
    "# Calculate min, mean, max sales.\n",
    "min_sales = min(sales_values)\n",
    "mean_sales = sum(sales_values) / len(sales_values)\n",
    "max_sales = max(sales_values)\n",
    "\n",
    "# Print results\n",
    "print(\"------ QUICK PROFILING ------\")\n",
    "print(f\"Minimum Sales: {min_sales:.2f}\")\n",
    "print(f\"Mean Sales: {mean_sales:.2f}\")\n",
    "print(f\"Maximum Sales: {max_sales:.2f}\")\n",
    "print(f\"Number of Unique Cities: {len(unique_cities)}\")\n",
    "print(f\"Sample Cities: {list(unique_cities)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fbb9d6",
   "metadata": {},
   "source": [
    "### **Step 6:** Spot the Grime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "677e46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- DIRTY DATA CASES FOUND -----\n",
      "Total dirty data cases: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Purpose:\n",
    "# Identify at least three types of dirty data in the sales dataset:\n",
    "# 1. Negative sales values (sales cannot be negative)\n",
    "# 2. Non-positive quantity (quantity should be at least 1)\n",
    "# 3. Missing or invalid city names (must be a non-empty string)\n",
    "\n",
    "# List to store details of all dirty data cases found\n",
    "dirty_cases = []\n",
    "\n",
    "# Loop through each transaction object in the transactions list\n",
    "for t in transactions:\n",
    "    # Check for negative sales\n",
    "    if t.sales < 0:\n",
    "        dirty_cases.append({\n",
    "            'issue': 'Negative Sales',\n",
    "            'order_id': t.order_id,\n",
    "            'sales': t.sales,\n",
    "            'city': t.city\n",
    "        })\n",
    "        \n",
    "    # Check for zero or negative quantity\n",
    "    if t.quantity <= 0:\n",
    "        dirty_cases.append({\n",
    "            'issue': 'Non-positive Quantity',\n",
    "            'order_id': t.order_id,\n",
    "            'quantity': t.quantity,\n",
    "            'city': t.city\n",
    "        })\n",
    "    \n",
    "    # Check for missing, empty, or invalid city names\n",
    "    if not isinstance(t.city, str) or not t.city.strip():\n",
    "        dirty_cases.append({\n",
    "            'issue': 'Missing or Invalid City',\n",
    "            'order_id': t.order_id,\n",
    "            'city': t.city,\n",
    "            'sales': t.sales\n",
    "        })\n",
    "\n",
    "# Print a summary of findings\n",
    "print(\"----- DIRTY DATA CASES FOUND -----\")\n",
    "print(f\"Total dirty data cases: {len(dirty_cases)}\\n\")\n",
    "\n",
    "# Show up to 5 sample dirty data cases for quick review\n",
    "for i, case in enumerate(dirty_cases[:5]):\n",
    "    print(f\"Case {i+1}: {case}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c896b",
   "metadata": {},
   "source": [
    "### **Step 7:** Cleaning Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "ef3ce663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- DATA CLEANING REPORT -----\n",
      "Records before cleaning: 500\n",
      "Records after cleaning:  500\n",
      "Records removed:         0\n"
     ]
    }
   ],
   "source": [
    "def clean(transactions):\n",
    "    \"\"\"\n",
    "    Cleans the transaction list by removing:\n",
    "    - Negative sales\n",
    "    - Non-positive (zero or negative) quantity\n",
    "    - Missing, empty, or invalid city names\n",
    "    Prints before/after counts.\n",
    "    \"\"\"\n",
    "    before_count = len(transactions)\n",
    "\n",
    "    cleaned_transactions = []\n",
    "    for t in transactions:\n",
    "        if t.sales < 0:\n",
    "            continue\n",
    "        if t.quantity <= 0:\n",
    "            continue\n",
    "        if not isinstance(t.city, str) or not t.city.strip():\n",
    "            continue\n",
    "        cleaned_transactions.append(t)\n",
    "    \n",
    "    after_count = len(cleaned_transactions)\n",
    "    print(\"\\n----- DATA CLEANING REPORT -----\")\n",
    "    print(f\"Records before cleaning: {before_count}\")\n",
    "    print(f\"Records after cleaning:  {after_count}\")\n",
    "    print(f\"Records removed:         {before_count - after_count}\")\n",
    "\n",
    "    return cleaned_transactions\n",
    "\n",
    "# Usage:\n",
    "transactions_clean = clean(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00db3a",
   "metadata": {},
   "source": [
    "### **Step 8:** Transformations\n",
    "\n",
    "Extract a numeric discount from product_name if present in the form '10%OFF'.\n",
    "Returns the integer discount (e.g., 10) or 0 if not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "950f9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_discount(product_name):\n",
    "    \n",
    "    for word in product_name.split():\n",
    "        if word.endswith('%OFF'):\n",
    "            try:\n",
    "                return int(word.replace('%OFF', ''))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return 0\n",
    "\n",
    "for t in transactions_clean:\n",
    "    t.discount = parse_discount(t.product_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec43d13",
   "metadata": {},
   "source": [
    "### **Step 9:** Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "c285ba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ DAYS SINCE PURCHASE ------\n",
      "Order Date: 2016-11-08, Days Since Purchase: 3122\n",
      "Order Date: 2016-11-08, Days Since Purchase: 3122\n",
      "Order Date: 2016-06-12, Days Since Purchase: 3271\n",
      "Order Date: 2015-10-11, Days Since Purchase: 3516\n",
      "Order Date: 2015-10-11, Days Since Purchase: 3516\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today()\n",
    "for t in transactions_clean:\n",
    "    # Difference in days between now and order_date\n",
    "    t.days_since_purchase = (today - t.order_date).days\n",
    "\n",
    "# Show sample\n",
    "print(\"\\n------ DAYS SINCE PURCHASE ------\")\n",
    "for t in transactions_clean[:5]:\n",
    "    print(f\"Order Date: {t.order_date.date()}, Days Since Purchase: {t.days_since_purchase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8fd00",
   "metadata": {},
   "source": [
    "### **Step 10:** Mini-Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "2c8bab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Top 10 Cities by Total Revenue ------\n",
      "New York City: $15037.80\n",
      "Houston: $11566.00\n",
      "San Antonio: $10546.57\n",
      "Los Angeles: $8991.52\n",
      "San Francisco: $8308.86\n",
      "Chicago: $6762.27\n",
      "Philadelphia: $6264.84\n",
      "Franklin: $4181.40\n",
      "Lakeville: $3745.63\n",
      "San Diego: $3364.07\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Calculate total revenue per city\n",
    "city_revenue = defaultdict(float)\n",
    "for t in transactions_clean:\n",
    "    city_revenue[t.city] += t.sales\n",
    "\n",
    "# Sort cities by revenue in descending order and take the top 10\n",
    "top_10_cities = sorted(city_revenue.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"\\n------ Top 10 Cities by Total Revenue ------\")\n",
    "for city, revenue in top_10_cities:\n",
    "    print(f\"{city}: ${revenue:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487a7692",
   "metadata": {},
   "source": [
    "### **Step 11:** Serialization Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "11f66371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\singh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (20.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "3b729e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized to JSON and Parquet.\n"
     ]
    }
   ],
   "source": [
    "from pandas.io.parquet import to_parquet\n",
    "\n",
    "# Convert back to DataFrame for saving (best for parquet/json)\n",
    "df_cleaned = pd.DataFrame([t.__dict__ for t in transactions_clean])\n",
    "df_cleaned.to_json(\"final_cleaned_transactions_data.json\", orient=\"records\", lines=True)\n",
    "df_cleaned.to_parquet(\"final_cleaned_transactions_data.parquet\")\n",
    "print(\"Serialized to JSON and Parquet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e5d9a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
